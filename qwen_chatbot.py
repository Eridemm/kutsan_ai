import tkinter as tk
from tkinter import scrolledtext, messagebox, ttk
import threading
import json
from datetime import datetime
from pathlib import Path
from collections import deque

import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

class QwenChatbot:
    def __init__(self, model_name="X-D-Lab/MindChat-Qwen2-4B", hf_token=None):
        self.model_name = model_name
        self.hf_token = hf_token
        self.model = None
        self.tokenizer = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.chat_history = deque(maxlen=50)  # Son 50 mesajƒ± tut
        self.is_loading = False
        self.max_new_tokens = 128  # 256'dan 128'e d√º≈ü√ºr√ºld√º - 2x hƒ±zlƒ±
        self.temperature = 0.8  # Daha √ße≈üitli ama hƒ±zlƒ± yanƒ±tlar
        self.top_p = 0.95  # Daha geni≈ü token se√ßimi
        self.repetition_penalty = 1.1  # Tekrar √∂nleme
        
    def load_model(self):
        """Modeli float16 ile y√ºkle (bitsandbytes CUDA hatasƒ± √ß√∂z√ºm√º)"""
        try:
            print(f"[INFO] Cihaz: {self.device}")
            print(f"[INFO] Model y√ºkleniyor: {self.model_name}")
            
            # Tokenizer y√ºkle
            self.tokenizer = AutoTokenizer.from_pretrained(
                self.model_name,
                token=self.hf_token,
                trust_remote_code=True
            )
            
            # 8-bit quantization RTX 3060 6GB i√ßin yeterli (~4-5GB VRAM kullanƒ±r)
            self.model = AutoModelForCausalLM.from_pretrained(
                self.model_name,
                load_in_8bit=True,  # 8-bit quantization
                device_map="auto",  # Otomatik GPU memory y√∂netimi
                token=self.hf_token,
                trust_remote_code=True,
                attn_implementation="sdpa",  # scaled dot product attention (PyTorch 2.0+)
                use_cache=True,  # KV cache kullan - 30-40% hƒ±zlanma
                low_cpu_mem_usage=True  # RAM tasarrufu
            )
            
            self.model.eval()
            
            print("[SUCCESS] Model ba≈üarƒ±yla y√ºklendi!")
            print(f"[INFO] VRAM kullanƒ±mƒ±: ~4-5GB (8-bit quantization)")
            print(f"[INFO] KV cache: Aktif - Hƒ±zlƒ± yanƒ±tlar i√ßin optimize edildi")
            return True
            
        except Exception as e:
            print(f"[ERROR] Model y√ºkleme hatasƒ±: {str(e)}")
            print("\n[INFO] Alternatif y√ºkleme deneniyor (float16, quantization yok)...")
            
            try:
                self.model = AutoModelForCausalLM.from_pretrained(
                    self.model_name,
                    device_map="auto",
                    token=self.hf_token,
                    trust_remote_code=True,
                    torch_dtype=torch.float16,
                    attn_implementation="sdpa",
                    use_cache=True,
                    low_cpu_mem_usage=True
                )
                self.model.eval()
                print("[SUCCESS] Model float16 ile y√ºklendi!")
                print("[WARNING] Quantization yok - VRAM kullanƒ±mƒ± ~6-8GB")
                return True
            except Exception as e2:
                print(f"[ERROR] Float16 y√ºkleme de ba≈üarƒ±sƒ±z: {str(e2)}")
                return False
    
    def add_to_history(self, role, content):
        """Chat ge√ßmi≈üine mesaj ekle"""
        self.chat_history.append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
    
    def get_chat_context(self):
        """Chat ge√ßmi≈üinden format edilmi≈ü context olu≈ütur"""
        messages = []
        for msg in self.chat_history:
            messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        return messages
    
    def generate_response(self, user_message):
        """Kullanƒ±cƒ± mesajƒ±na yanƒ±t √ºret"""
        try:
            if self.model is None:
                return "[ERROR] Model hen√ºz y√ºklenmedi!"
            
            # Ge√ßmi≈üe kullanƒ±cƒ± mesajƒ±nƒ± ekle
            self.add_to_history("user", user_message)
            
            # Context'i hazƒ±rla
            messages = self.get_chat_context()
            
            # Chat template uygula
            inputs = self.tokenizer.apply_chat_template(
                messages,
                add_generation_prompt=True,
                tokenize=True,
                return_tensors="pt",
                return_dict=True
            ).to(self.model.device)
            
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=self.max_new_tokens,  # 128 token - daha hƒ±zlƒ±
                    temperature=self.temperature,
                    top_p=self.top_p,
                    do_sample=True,
                    repetition_penalty=self.repetition_penalty,  # Tekrar √∂nleme
                    pad_token_id=self.tokenizer.eos_token_id,
                    use_cache=True,  # KV cache kullan
                    num_beams=1,  # Beam search yok - greedy daha hƒ±zlƒ±
                )
            
            # Yanƒ±tƒ± decode et (sadece yeni token'larƒ± al)
            response_text = self.tokenizer.decode(
                outputs[0][inputs["input_ids"].shape[-1]:],
                skip_special_tokens=True
            ).strip()
            
            # Ge√ßmi≈üe bot yanƒ±tƒ±nƒ± ekle
            self.add_to_history("assistant", response_text)
            
            return response_text
            
        except Exception as e:
            error_msg = f"[ERROR] Yanƒ±t √ºretme hatasƒ±: {str(e)}"
            print(error_msg)
            return error_msg
    
    def save_chat(self, filepath="chat_history.json"):
        """Chat ge√ßmi≈üini dosyaya kaydet"""
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(list(self.chat_history), f, ensure_ascii=False, indent=2)
            print(f"[SUCCESS] Chat kaydedildi: {filepath}")
        except Exception as e:
            print(f"[ERROR] Chat kaydetme hatasƒ±: {str(e)}")


class ChatbotGUI:
    def __init__(self, root, hf_token):
        self.root = root
        self.root.title("Qwen Chatbot - Turkish")
        self.root.geometry("900x700")
        self.hf_token = hf_token
        
        # Chatbot instance
        self.chatbot = QwenChatbot(hf_token=hf_token)
        self.model_loaded = False
        
        # GUI Bile≈üenleri
        self.setup_ui()
        
        # Model y√ºklemesini ba≈ülat
        self.load_model_thread()
    
    def setup_ui(self):
        """GUI aray√ºz√ºn√º olu≈ütur"""
        # Ana frame
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # Ba≈ülƒ±k
        title_label = ttk.Label(
            main_frame, 
            text="Qwen 2 4B T√ºrk√ße Chatbot", 
            font=("Arial", 16, "bold")
        )
        title_label.pack(pady=10)
        
        # Durum etiketi
        self.status_label = ttk.Label(
            main_frame,
            text="‚è≥ Model y√ºkleniyor...",
            font=("Arial", 10),
            foreground="orange"
        )
        self.status_label.pack()
        
        # Chat display alanƒ±
        chat_frame = ttk.LabelFrame(main_frame, text="Sohbet", padding=10)
        chat_frame.pack(fill=tk.BOTH, expand=True, pady=10)
        
        self.chat_display = scrolledtext.ScrolledText(
            chat_frame,
            height=20,
            width=80,
            wrap=tk.WORD,
            state=tk.DISABLED,
            font=("Arial", 10),
            bg="#f0f0f0"
        )
        self.chat_display.pack(fill=tk.BOTH, expand=True)
        
        # Mesaj giri≈ü alanƒ±
        input_frame = ttk.LabelFrame(main_frame, text="Mesaj G√∂nder", padding=10)
        input_frame.pack(fill=tk.X, pady=10)
        
        self.input_text = tk.Text(
            input_frame,
            height=3,
            width=70,
            font=("Arial", 10),
            wrap=tk.WORD
        )
        self.input_text.pack(side=tk.LEFT, fill=tk.BOTH, expand=True, padx=(0, 10))
        
        # G√∂nder butonu
        self.send_button = ttk.Button(
            input_frame,
            text="G√ñNDER\n(Ctrl+Enter)",
            command=self.send_message
        )
        self.send_button.pack(side=tk.RIGHT, fill=tk.BOTH)
        
        # Kontrol frame
        control_frame = ttk.Frame(main_frame)
        control_frame.pack(fill=tk.X, pady=10)
        
        # Ayarlar
        settings_frame = ttk.LabelFrame(control_frame, text="Ayarlar", padding=10)
        settings_frame.pack(side=tk.LEFT, fill=tk.X, expand=True, padx=(0, 10))
        
        ttk.Label(settings_frame, text="Temperature (0-2):").pack(side=tk.LEFT, padx=5)
        self.temp_scale = ttk.Scale(
            settings_frame,
            from_=0,
            to=2,
            orient=tk.HORIZONTAL,
            length=150
        )
        self.temp_scale.set(0.7)
        self.temp_scale.pack(side=tk.LEFT, padx=5)
        
        ttk.Label(settings_frame, text="Top-P (0-1):").pack(side=tk.LEFT, padx=5)
        self.top_p_scale = ttk.Scale(
            settings_frame,
            from_=0,
            to=1,
            orient=tk.HORIZONTAL,
            length=150
        )
        self.top_p_scale.set(0.9)
        self.top_p_scale.pack(side=tk.LEFT, padx=5)
        
        # Butonlar
        button_frame = ttk.Frame(control_frame)
        button_frame.pack(side=tk.RIGHT, fill=tk.X)
        
        ttk.Button(button_frame, text="Temizle", command=self.clear_chat).pack(side=tk.LEFT, padx=5)
        ttk.Button(button_frame, text="Kaydet", command=self.save_chat).pack(side=tk.LEFT, padx=5)
        
        # Keyboard binding
        self.root.bind("<Control-Return>", lambda e: self.send_message())
    
    def load_model_thread(self):
        """Modeli ayrƒ± thread'de y√ºkle"""
        def load():
            if self.chatbot.load_model():
                self.model_loaded = True
                self.status_label.config(
                    text="‚úì Model hazƒ±r! Mesaj g√∂nderebilirsiniz.",
                    foreground="green"
                )
                self.send_button.config(state=tk.NORMAL)
                self.input_text.config(state=tk.NORMAL)
            else:
                self.status_label.config(
                    text="‚úó Model y√ºkleme ba≈üarƒ±sƒ±z!",
                    foreground="red"
                )
                messagebox.showerror("Hata", "Model y√ºkleme ba≈üarƒ±sƒ±z oldu!")
        
        self.send_button.config(state=tk.DISABLED)
        self.input_text.config(state=tk.DISABLED)
        
        thread = threading.Thread(target=load, daemon=True)
        thread.start()
    
    def send_message(self, event=None):
        """Mesajƒ± g√∂nder ve yanƒ±t al"""
        if not self.model_loaded:
            messagebox.showwarning("Uyarƒ±", "Model hen√ºz y√ºklenmedi!")
            return
        
        message = self.input_text.get("1.0", tk.END).strip()
        if not message:
            return
        
        # Temperature ve Top-P g√ºncelle
        self.chatbot.temperature = float(self.temp_scale.get())
        self.chatbot.top_p = float(self.top_p_scale.get())
        
        # Chat ekranƒ±nƒ± g√ºncelle
        self.chat_display.config(state=tk.NORMAL)
        self.chat_display.insert(tk.END, f"\nüë§ Siz: {message}\n", "user")
        self.chat_display.see(tk.END)
        self.chat_display.config(state=tk.DISABLED)
        
        self.input_text.delete("1.0", tk.END)
        self.send_button.config(state=tk.DISABLED)
        
        # Yanƒ±tƒ± ayrƒ± thread'de √ºret
        def generate():
            response = self.chatbot.generate_response(message)
            self.root.after(0, self.display_response, response)
            self.send_button.config(state=tk.NORMAL)
        
        thread = threading.Thread(target=generate, daemon=True)
        thread.start()
    
    def display_response(self, response):
        """Yanƒ±tƒ± ekranda g√∂ster"""
        self.chat_display.config(state=tk.NORMAL)
        self.chat_display.insert(tk.END, f"\nü§ñ Bot: {response}\n", "assistant")
        self.chat_display.see(tk.END)
        self.chat_display.config(state=tk.DISABLED)
    
    def clear_chat(self):
        """Sohbeti temizle"""
        self.chat_display.config(state=tk.NORMAL)
        self.chat_display.delete("1.0", tk.END)
        self.chat_display.config(state=tk.DISABLED)
        self.chatbot.chat_history.clear()
    
    def save_chat(self):
        """Sohbeti kaydet"""
        self.chatbot.save_chat()
        messagebox.showinfo("Ba≈üarƒ±lƒ±", "Sohbet kaydedildi: chat_history.json")


if __name__ == "__main__":
    # TOKEN'ƒ∞ BURAYA YAPISTIR (hardcoded)
    HF_TOKEN = "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"
    
    root = tk.Tk()
    gui = ChatbotGUI(root, HF_TOKEN)
    root.mainloop()
