# Qwen TÃ¼rkÃ§e Chatbot - Kurulum Rehberi

## Sistem Gereksinimleri

- **OS**: Windows 10+, Linux, macOS
- **RAM**: Minimum 16GB (Ã¶nerilen 24GB+)
- **GPU**: NVIDIA CUDA Compute Capability 6.0+ (RTX 3060+)
  - VRAM: 6GB+ (4-bit quantization ile)
- **Python**: 3.9+
- **CUDA Toolkit**: 11.8+ (GPU kullanÄ±yorsanÄ±z)

## HÄ±zlÄ± Kurulum (3 AdÄ±m)

### 1. Virtual Environment OluÅŸtur ve Paketleri YÃ¼kle

\`\`\`bash
# Virtual environment oluÅŸtur
python -m venv qwen_env

# AktifleÅŸtir
# Windows:
qwen_env\Scripts\activate
# Linux/macOS:
source qwen_env/bin/activate

# Requirements yÃ¼kle
pip install -r requirements.txt

# PyTorch CUDA 11.8 ile yÃ¼kle
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
\`\`\`

### 2. Token AyarÄ± (Zaten Hardcoded)

Token script'te hardcoded olarak gelir: `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`

FarklÄ± token kullanmak istersen:
\`\`\`python
# qwen_chatbot.py satÄ±rÄ± 225'te:
HF_TOKEN = "hf_YourTokenHere"
\`\`\`

### 3. Ã‡alÄ±ÅŸtÄ±r

\`\`\`bash
python qwen_chatbot.py
\`\`\`

## Ä°lk Ã‡alÄ±ÅŸtÄ±rma

- Model ilk kez indirilecek (~8-12 GB)
- Ä°nternet baÄŸlantÄ±sÄ± gerekli
- 10-20 dakika sÃ¼rebilir
- Sonraki Ã§alÄ±ÅŸtÄ±rmalar anlÄ±k aÃ§Ä±lacak

## CUDA Kurulumu (GPU KullanÄ±yorsanÄ±z)

### Windows:
1. CUDA Toolkit 11.8 indir: https://developer.nvidia.com/cuda-11-8-0-download-wizard
2. cuDNN indir: https://developer.nvidia.com/cudnn
3. cuDNN dosyalarÄ±nÄ± `C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8` iÃ§ine kopyala

### Linux (Ubuntu):
\`\`\`bash
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/3bf863cc.pub
sudo add-apt-repository "deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /"
sudo apt-get update
sudo apt-get -y install cuda-11-8
\`\`\`

## Sorun Giderme

### Problem: "CUDA out of memory"
8-bit quantization kullan:
\`\`\`python
# qwen_chatbot.py satÄ±r 48-53'te:
bnb_config = BitsAndBytesConfig(
    load_in_8bit=True,  # 4bit yerine
    bnb_8bit_use_double_quant=True,
    bnb_8bit_quant_type="nf4",
    bnb_8bit_compute_dtype=torch.bfloat16
)
\`\`\`

### Problem: "Model not found"
- Token'Ä± kontrol et
- Ä°nternet baÄŸlantÄ±sÄ±nÄ± kontrol et
- Model var mÄ± kontrol et: https://huggingface.co/X-D-Lab/MindChat-Qwen2-4B

### Problem: "CUDA not available"
GPU yÃ¼klemesi baÅŸarÄ±sÄ±z olursa CPU'da otomatik Ã§alÄ±ÅŸÄ±r (yavaÅŸ olur):
\`\`\`bash
nvidia-smi  # GPU'nuzun tanÄ±ndÄ±ÄŸÄ±nÄ± kontrol edin
\`\`\`

### Problem: Uzun yanÄ±t sÃ¼releri
- Temperature deÄŸerini azalt (0.5-0.6)
- Top-P deÄŸerini azalt (0.7-0.8)
- `max_new_tokens` deÄŸerini kÃ¼Ã§Ã¼lt (qwen_chatbot.py satÄ±r 23, Ã¶rn: 128)

## Performans Ä°puÃ§larÄ±

1. **Ä°lk Ã§alÄ±ÅŸtÄ±rma**: Model cache'lenir, sonraki aÃ§Ä±lÄ±ÅŸlar anlÄ±k
2. **Temperature (0.7)**: DÃ¼ÅŸÃ¼k = daha sabit, YÃ¼ksek = daha yaratÄ±cÄ±
3. **Top-P (0.9)**: Ã‡eÅŸitliliÄŸi kontrol eder (dÃ¼ÅŸÃ¼k = tekrarlÄ±, yÃ¼ksek = daha Ã§eÅŸitli)
4. **Chat History**: Son 50 mesaj tutulur, context-aware sohbet saÄŸlanÄ±r

## GPU KullanÄ±mÄ±nÄ± Ä°zleme

\`\`\`bash
# Windows (PowerShell):
nvidia-smi -l 1

# Linux:
watch -n 1 nvidia-smi
\`\`\`

## Web'e TaÅŸÄ±ma (Sonraki AÅŸama)

Daha sonra FastAPI kullanarak REST API'ye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lebilir:

\`\`\`python
from fastapi import FastAPI
app = FastAPI()
chatbot = QwenChatbot()

@app.post("/chat")
async def chat(message: str):
    response = chatbot.generate_response(message)
    return {"response": response}
\`\`\`

SonrasÄ±nda Docker ve Cloud Deploy (Vercel, Railway, Heroku) yapÄ±labilir.

## BaÅŸladÄ±n mÄ±?

1. `pip install -r requirements.txt`
2. `python qwen_chatbot.py`
3. Merhaba de!

Soruna yaÅŸarsan direkt sor! ğŸš€
